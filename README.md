# ðŸ¤– AI Dev Team

Sistema multi-agente que transforma un brief en una aplicaciÃ³n funcional completa.

Recibe una descripciÃ³n de lo que quieres construir, y un pipeline de 9 agentes de IA
(BA, PO, Arquitecto, Evaluador, Backend Builder, Frontend Builder, QA, IntegraciÃ³n, DevOps)
genera requerimientos, historias de usuario, arquitectura, cÃ³digo, tests y configuraciÃ³n
de despliegue â€” todo automatizado con revisiÃ³n humana en dos puntos clave.

## Stack

- **Backend (orquestador):** Python 3.11+ Â· FastAPI Â· LangGraph Â· Anthropic SDK
- **Frontend (panel de control):** React 18 Â· Vite Â· TailwindCSS
- **LLM:** Multi-proveedor â€” Anthropic, OpenAI, Groq, Gemini, Kimi, Mistral

## Requisitos previos

- Python 3.11+
- Node.js 18+
- Una API key de Anthropic (o del provider que elijas)

## Setup rÃ¡pido

### 1. Clonar y configurar variables de entorno

```bash
git clone <repo-url>
cd ai-dev-team
cp .env.example .env
# Edita .env y agrega tu ANTHROPIC_API_KEY
```

### 2. Backend

```bash
python -m venv venv

# Activar entorno virtual
# Windows:
venv\Scripts\activate
# macOS/Linux:
source venv/bin/activate

pip install -r requirements.txt
```

### 3. Frontend

```bash
cd frontend
npm install
npm run build
cd ..
```

### 4. Ejecutar

Necesitas dos terminales:

**Terminal 1 â€” Backend (puerto 8000):**
```bash
uvicorn backend.main:app --reload --port 8000
```

**Terminal 2 â€” Frontend (puerto 5173):**
```bash
cd frontend
npm run dev
```

Abre http://localhost:5173 en tu navegador.

## CÃ³mo funciona

1. **Nuevo Run** â€” Escribe un brief describiendo la aplicaciÃ³n que quieres
2. **Pipeline automÃ¡tico** â€” Los agentes trabajan en secuencia:
   - BA analiza requerimientos â†’ PO prioriza y define MVP â†’ Arquitecto diseÃ±a â†’ Evaluador valida
3. **Gate 1** â€” Revisas la planificaciÃ³n y apruebas (o pides cambios)
4. **ConstrucciÃ³n** â€” Backend y Frontend builders generan cÃ³digo en paralelo â†’ QA genera tests
5. **IntegraciÃ³n** â€” ValidaciÃ³n cruzada del cÃ³digo generado
6. **Gate 2** â€” Revisas el cÃ³digo y apruebas
7. **DevOps** â€” Genera Dockerfile, docker-compose, nginx, README
8. **Exportar** â€” Descarga un ZIP con el proyecto completo listo para `docker-compose up`

## Estructura del proyecto

```
â”œâ”€â”€ backend/              # Orquestador multi-agente (FastAPI + LangGraph)
â”‚   â”œâ”€â”€ agents/           # 9 agentes especializados
â”‚   â”œâ”€â”€ api/              # Endpoints REST
â”‚   â”œâ”€â”€ graph/            # Workflow LangGraph (state, nodes, edges)
â”‚   â””â”€â”€ services/         # Servicio LLM (Anthropic/OpenAI/Groq/Kimi)
â”œâ”€â”€ frontend/             # Panel de control (React + Vite + Tailwind)
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ components/   # PipelineTracker, ArtifactsPanel, FilesPanel, etc.
â”‚       â”œâ”€â”€ pages/        # HomePage, RunPage, RunsListPage
â”‚       â””â”€â”€ services/     # Cliente API (axios)
â”œâ”€â”€ app/                  # Output: aquÃ­ se exportan las apps generadas
â”œâ”€â”€ exports/              # ZIPs descargables
â”œâ”€â”€ .env.example          # Template de configuraciÃ³n
â””â”€â”€ requirements.txt      # Dependencias Python
```

## API Endpoints

| MÃ©todo | Ruta | DescripciÃ³n |
|--------|------|-------------|
| POST | `/api/runs` | Iniciar un nuevo run con un brief |
| GET | `/api/runs` | Listar todos los runs |
| GET | `/api/runs/{id}` | Estado actual de un run |
| GET | `/api/runs/{id}/artifacts` | Artefactos generados |
| GET | `/api/runs/{id}/files` | Archivos generados con contenido |
| GET | `/api/runs/{id}/decisions` | Log de decisiones de agentes |
| POST | `/api/runs/{id}/hitl` | Enviar decisiÃ³n HITL (aprobar/rechazar) |
| POST | `/api/runs/{id}/export` | Exportar proyecto a app/ + ZIP |
| GET | `/api/runs/{id}/download` | Descargar ZIP |
| POST | `/api/deploy` | Desplegar con docker-compose |
| POST | `/api/teardown` | Detener contenedores |

## ConfiguraciÃ³n LLM

Cada agente usa su propio modelo, configurable por variable de entorno. El formato es `provider/model-id`.

### Variables de entorno

```bash
# Fallback para agentes sin override explÃ­cito
DEFAULT_MODEL=anthropic/claude-sonnet-4-6

# API keys â€” solo las del provider que uses
ANTHROPIC_API_KEY=sk-ant-...
OPENAI_API_KEY=sk-...
GROQ_API_KEY=gsk_...
GEMINI_API_KEY=...

# Modelo por agente (opcional â€” si no se define, usa DEFAULT_MODEL)
MODEL_BA=anthropic/claude-sonnet-4-6
MODEL_PO=anthropic/claude-sonnet-4-6
MODEL_ARCHITECT=anthropic/claude-opus-4-6
MODEL_BACKEND=anthropic/claude-sonnet-4-6
MODEL_FRONTEND=anthropic/claude-sonnet-4-6
MODEL_QA=anthropic/claude-haiku-4-5-20251001
MODEL_VALIDATOR=anthropic/claude-opus-4-6
MODEL_DEVOPS=anthropic/claude-haiku-4-5-20251001
MODEL_EVALUATOR=anthropic/claude-sonnet-4-6
```

### Providers soportados

| Provider | Formato | API Key |
|----------|---------|---------|
| Anthropic | `anthropic/claude-sonnet-4-6` | `ANTHROPIC_API_KEY` |
| OpenAI | `openai/gpt-4o` | `OPENAI_API_KEY` |
| Groq | `groq/llama-3.3-70b-versatile` | `GROQ_API_KEY` |
| Gemini | `gemini/gemini-1.5-pro` | `GEMINI_API_KEY` |
| Kimi | `kimi/moonshot-v1-8k` | `KIMI_API_KEY` |
| Mistral | `mistral/mistral-large-latest` | `MISTRAL_API_KEY` |

Puedes mezclar proveedores libremente â€” por ejemplo, Anthropic Opus para el Arquitecto y Groq para los builders.
